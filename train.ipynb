{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e62d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.trainers import PixelwiseRegressionTask\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import cv2\n",
    "import logging\n",
    "from typing import List\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "from utils.model import LSTNowcaster\n",
    "from utils.data.TiledLandsatDataModule import TiledLandsatDataModule\n",
    "from utils.voice import notifySelf\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"TrainUNet-Basic.ipynb\"\n",
    "os.environ[\"WANDB_DIR\"] = \"./wandb\"\n",
    "os.environ[\"WANDB_CACHE_DIR\"] = \"./wandb/.cache/wandb\"\n",
    "os.environ[\"WANDB_CONFIG_DIR\"] = \"./wandb/.config/wandb\"\n",
    "os.environ[\"WANDB_DATA_DIR\"] = \"./wandb/.cache/wandb-data\"\n",
    "os.environ[\"WANDB_ARTIFACT_DIR\"] = \"./wandb/artifacts\"\n",
    "import sys\n",
    "\n",
    "i = -1\n",
    "batchSize = 64\n",
    "deviceCount = 1\n",
    "# Get the first argument passed after the script name\n",
    "# if len(sys.argv) > 1:\n",
    "#     i = int(sys.argv[1])  # Convert string to integer\n",
    "#     batchSize = int(sys.argv[2])\n",
    "#     deviceCount = int(sys.argv[3])\n",
    "config = {\n",
    "    \"experiment_name\": \"test\",\n",
    "    \"debug\": False,\n",
    "    \"by_city\": False,\n",
    "    \"months_ahead\": 1,\n",
    "    \"tile_size\": 128,\n",
    "    \"tile_overlap\": 0.0,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"model\": \"segformer\",\n",
    "    \"backbone\": \"b5\",\n",
    "    \"dataset\": \"pure_landsat\",\n",
    "    \"augment\": True,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": batchSize,\n",
    "    \"pretrained_weights\": True,\n",
    "    \"deterministic\": True,\n",
    "    \"random_seed_by_scene\": 1,\n",
    "    \"in_channels\": 6,\n",
    "    \"only_train\": False,\n",
    "    \"skip_years\": []\n",
    "}\n",
    "\n",
    "# Original 12 experiments from results table in the research paper\n",
    "if i == 1:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b5\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 2:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b5\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 3:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b3\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 4:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b3\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 5:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 6:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "#b3\n",
    "if i == 7:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 8:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 9:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 10:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 11:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 12:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i <= -1:\n",
    "    pass\n",
    "else:\n",
    "    config[\"experiment_name\"] = f'Exp. #{i}: {config[\"model\"]},Month {config[\"months_ahead\"]}, {config[\"backbone\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e9fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find TrainUNet-Basic.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjesus-guerrero\u001b[0m (\u001b[33mjesus-guerrero-ml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/wandb/run-20250523_132004-f9smq9br</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/f9smq9br' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/f9smq9br' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island/runs/f9smq9br</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/.conda/envs/ml/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /work/ubh496/.conda/envs/ml/lib/python3.10/site-pack ...\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 2226/2226 [00:00<00:00, 1178704.80it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 318/318 [00:00<00:00, 333.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits - Train: 254, Val: 32, Test: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 2226/2226 [00:00<00:00, 1172340.62it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 318/318 [00:00<00:00, 3621.16it/s]\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits - Train: 254, Val: 32, Test: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb8f501c48f4197bc479f11f6b59752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/testDataset/lst-benchmark/utils/model.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e026d52e4deb4db7ac22dedcf8161812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4419a0c25742969ca615e6ad0037e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39686e719183463bacfaf8726c7db3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished test...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "notifySelf(f'Starting {config[\"experiment_name\"]}!')\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"heat-island\",\n",
    "    name=config['experiment_name'],\n",
    "    log_model=\"best\",\n",
    "    save_code=True,\n",
    "    save_dir=\"./wandb\",\n",
    ")\n",
    "wandb_logger.log_hyperparams(config)    \n",
    "\n",
    "# Create model\n",
    "model = LSTNowcaster(\n",
    "    model=config[\"model\"], \n",
    "    backbone=config[\"backbone\"], \n",
    "    in_channels=config[\"in_channels\"], \n",
    "    learning_rate=config[\"learning_rate\"], \n",
    "    pretrained_weights=config[\"pretrained_weights\"]\n",
    ")\n",
    "\n",
    "class PercentageProgressCallback(Callback):\n",
    "    def __init__(self, total_epochs, experiment_name):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Only run on main process\n",
    "        if trainer.is_global_zero:\n",
    "            current_epoch = trainer.current_epoch\n",
    "            if current_epoch % 20 == 0:\n",
    "                current_percentage = min(100, int(current_epoch / self.total_epochs * 100))\n",
    "                wandb.alert(title=\"Training Update\", \n",
    "                        text=f'{self.experiment_name} is at {current_percentage:.2f}%', \n",
    "                        level=wandb.AlertLevel.INFO)\n",
    "\n",
    "percentage_callback = PercentageProgressCallback(total_epochs=config[\"epochs\"], experiment_name=config[\"experiment_name\"])    \n",
    "wandb_run_id = wandb_logger.experiment.id    \n",
    "current_date = datetime.now()                \n",
    "date_string = current_date.strftime(\"%B%d\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"./wandb/heat-island/checkpoints/{wandb_run_id}_{date_string}\",\n",
    "    filename= f\"{wandb_run_id}_{date_string}_\" + \"{epoch:03d}_{val_rmse_F:.4f}\",\n",
    "    monitor=\"val_rmse_p\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False  # Also save the last model for comparison\n",
    ")\n",
    "allYears = [\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "for year in config[\"skip_years\"]:\n",
    "    allYears.remove(year)\n",
    "# for subYears in [allYears[:5], allYears[5:]]:\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config['epochs'],\n",
    "    gradient_clip_val=0.5,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=False,\n",
    "    # deterministic=config[\"deterministic\"],\n",
    "    num_sanity_val_steps=2,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, percentage_callback],\n",
    "    # devices=deviceCount,                         # Use all 4 GPUs\n",
    "    accelerator=\"gpu\",                 # Use GPU acceleration\n",
    "    # strategy=\"ddp\",                    # Use DistributedDataParallel\n",
    "    precision=\"16-mixed\"               # Add mixed precision for memory efficiency\n",
    ")                             \n",
    "\n",
    "data_module = TiledLandsatDataModule(\n",
    "    data_dir=\"./Data\",\n",
    "    monthsAhead=config[\"months_ahead\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=8,\n",
    "    byCity=config[\"by_city\"],\n",
    "    debug=config[\"debug\"],\n",
    "    tile_size=config[\"tile_size\"],\n",
    "    tile_overlap=config[\"tile_overlap\"],\n",
    "    augment=config[\"augment\"],\n",
    "    seedForScene=config[\"random_seed_by_scene\"],\n",
    "    onlyTrain = config[\"only_train\"],\n",
    "    includeYears=allYears\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "# Train model\n",
    "trainer.fit(model=model, datamodule=data_module)\n",
    "\n",
    "# Register the best model as a W&B artifact\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "if best_model_path and os.path.exists(best_model_path):\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f\"{best_model_path.split('/')[-1].replace('=','.')}\", \n",
    "        type=\"model\",\n",
    "        description=f\"Best model at {best_model_path.split('/')[-1]}\" \n",
    "    )\n",
    "    artifact.add_file(best_model_path)\n",
    "    wandb_logger.experiment.log_artifact(artifact)\n",
    "\n",
    "notifySelf(f\"Finished {config['experiment_name']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af8d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to run multiple experiments using arguments, free GPU memory with this...\n",
    "    # del trainer\n",
    "    # del data_module\n",
    "    # # Force garbage collection and clear CUDA cache\n",
    "    # import gc\n",
    "    # gc.collect()\n",
    "    # torch.cuda.empty_cache()\n",
    "    # # After deleting objects\n",
    "    # for i in range(torch.cuda.device_count()):\n",
    "    #     with torch.cuda.device(i):\n",
    "    #         torch.cuda.empty_cache()\n",
    "    # del model\n",
    "    # del wandb_logger\n",
    "    # del checkpoint_callback\n",
    "\n",
    "    # # Force garbage collection and clear CUDA cache\n",
    "    # import gc\n",
    "    # for obj in gc.get_objects():   \n",
    "    #     try:\n",
    "    #         if torch.is_tensor(obj) and obj.device.type == 'cuda':\n",
    "    #             del obj\n",
    "    #     except:\n",
    "    #         pass\n",
    "    # gc.collect()\n",
    "\n",
    "    # # After deleting objects\n",
    "    # for j in range(torch.cuda.device_count()):\n",
    "    #     with torch.cuda.device(j):\n",
    "    #         x = torch.zeros(1024, 1024, 1024, device=f'cuda:{j}')\n",
    "    #         del x\n",
    "    #         torch.cuda.empty_cache()\n",
    "    #         torch.cuda.reset_peak_memory_stats()\n",
    "    #         torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "    # # 4. Wait for GPU processes to complete\n",
    "    # torch.cuda.synchronize()\n",
    "\n",
    "    # # Print memory stats for debugging\n",
    "    # if torch.cuda.is_available():\n",
    "    #     print(f\"Loop {i} completed. CUDA memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    #     print(f\"CUDA memory reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    # notifySelf(\"Batch experiment ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b7131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 2226/2226 [00:00<00:00, 1109245.66it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 318/318 [00:00<00:00, 2234.61it/s]\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits - Train: 254, Val: 32, Test: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e6c55e040e445082f81f0424f0fb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_rmse_F        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     16.31536293029785     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_rmse_P        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.163417816162109     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_rmse_F       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    16.31536293029785    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_rmse_P       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.163417816162109    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_rmse_F': 16.31536293029785, 'test_rmse_P': 4.163417816162109}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTNowcaster.load_from_checkpoint(\n",
    "    checkpoint_path=best_model_path,\n",
    ")\n",
    "\n",
    "trainer.test(model=model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbc2abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▅▅█</td></tr><tr><td>test_rmse_F</td><td>▁</td></tr><tr><td>test_rmse_P</td><td>▁</td></tr><tr><td>train_rmse_F</td><td>█▁</td></tr><tr><td>train_rmse_P</td><td>█▁</td></tr><tr><td>trainer/global_step</td><td>▁▁███</td></tr><tr><td>val_rmse_F</td><td>█▁</td></tr><tr><td>val_rmse_p</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>test_rmse_F</td><td>16.31536</td></tr><tr><td>test_rmse_P</td><td>4.16342</td></tr><tr><td>train_rmse_F</td><td>15.08326</td></tr><tr><td>train_rmse_P</td><td>3.88485</td></tr><tr><td>trainer/global_step</td><td>400</td></tr><tr><td>val_rmse_F</td><td>11.09669</td></tr><tr><td>val_rmse_p</td><td>3.57856</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test</strong> at: <a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/f9smq9br' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island/runs/f9smq9br</a><br> View project at: <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/wandb/run-20250523_132004-f9smq9br/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# End Experiment\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from utils.model import LSTNowcaster\n",
    "from utils.data.TiledLandsatDataModule import TiledLandsatDataModule\n",
    "\n",
    "# Define which model checkpoint to test\n",
    "# You can either specify a specific checkpoint or use the best one from a previous run\n",
    "for checkpoint_path in [\n",
    "    \"/home/ubuntu/heat-island-test/wandb/heat-island/checkpoints/up47iayb_April15/up47iayb_April15_epoch=059_val_rmse_F=17.0594.ckpt\"\n",
    "]:\n",
    "\n",
    "    # Initialize test configuration\n",
    "    test_config = {\n",
    "        \"experiment_name\": \"Test OneFormer Debug\",\n",
    "        \"debug\": True,  # Set to False for full test\n",
    "        \"by_city\": False,\n",
    "        \"months_ahead\": 3,\n",
    "        \"tile_size\": 128,\n",
    "        \"tile_overlap\": 0.0,\n",
    "        \"model\": \"segformer\",\n",
    "        \"backbone\": \"b5\",\n",
    "        \"dataset\": \"pure_landsat\",\n",
    "        \"batch_size\": 1,  # Can be larger than training since no gradients are stored\n",
    "        \"in_channels\": 6\n",
    "    }\n",
    "\n",
    "    # Get the run ID from your checkpoint path\n",
    "    run_id = checkpoint_path.split('/')[-2].split('_')[0]  # Extracts the run ID from the checkpoint path\n",
    "\n",
    "    # Initialize WandB logger that continues the same run\n",
    "    test_logger = WandbLogger(\n",
    "        project=\"heat-island\",\n",
    "        id=run_id,  # Use the same run ID to continue logging to the same run\n",
    "        resume=\"must\",  # Force resume the existing run\n",
    "        save_dir=\"./wandb\",\n",
    "    )\n",
    "\n",
    "    # Set up data module for testing\n",
    "    data_module = TiledLandsatDataModule(\n",
    "        data_dir=\"./Data\",\n",
    "        monthsAhead=test_config[\"months_ahead\"],\n",
    "        batch_size=test_config[\"batch_size\"],\n",
    "        num_workers=4,\n",
    "        byCity=test_config[\"by_city\"],\n",
    "        debug=test_config[\"debug\"],\n",
    "        tile_size=test_config[\"tile_size\"],\n",
    "        tile_overlap=test_config[\"tile_overlap\"],\n",
    "        augment=False,  # No augmentation during testing\n",
    "        seedForScene=1,  # Consistent seed for reproducibility\n",
    "        includeYears=[\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "    )\n",
    "    data_module.setup()  # Explicitly prepare the test data\n",
    "\n",
    "    # Initialize the model with the same architecture used during training\n",
    "    model = LSTNowcaster.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        model=test_config[\"model\"],\n",
    "        backbone=test_config[\"backbone\"],\n",
    "        in_channels=test_config[\"in_channels\"]\n",
    "    )\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize trainer specifically for testing\n",
    "    from pytorch_lightning import Trainer\n",
    "    test_trainer = Trainer(\n",
    "        logger=test_logger,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    # Run test\n",
    "    test_results = test_trainer.test(model=model, datamodule=data_module)\n",
    "\n",
    "    # Log detailed test metrics\n",
    "    test_logger.experiment.log({\n",
    "        \"test_results\": test_results[0],\n",
    "        \"test_rmse_F\": test_results[0].get(\"test_rmse_F\", None),\n",
    "        \"test_mae_F\": test_results[0].get(\"test_mae_F\", None)\n",
    "    })\n",
    "\n",
    "    # Clean up resources\n",
    "    del model\n",
    "    del test_trainer\n",
    "    del data_module\n",
    "    del test_logger\n",
    "\n",
    "    # Force garbage collection and clear CUDA cache\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Test complete. Results: {test_results}\")\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b654b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d865a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find TrainUNet-Basic.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjesus-guerrero\u001b[0m (\u001b[33mjesus-guerrero-ml\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to send email...\n",
      "(535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials d75a77b69052e-494ae3f88d1sm122175061cf.19 - gsmtp')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/wandb/run-20250523_230613-yekyxa2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/yekyxa2u' target=\"_blank\">Exp. #1-6 Channel: segformer,Month 1, b5</a></strong> to <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/yekyxa2u' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island/runs/yekyxa2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/.conda/envs/ml/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /work/ubh496/.conda/envs/ml/lib/python3.10/site-pack ...\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 30258/30258 [00:00<00:00, 1502370.56it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 405/405 [00:00<00:00, 534.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits - Train: 324, Val: 40, Test: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "INFO:lightning_fabric.utilities.distributed:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "INFO:pytorch_lightning.utilities.rank_zero:----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 2 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 30258/30258 [00:00<00:00, 1571481.20it/s]\n",
      "Gathering scenes (Sort by Random Scene)...: 100%|██████████| 30258/30258 [00:00<00:00, 1536846.54it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 405/405 [00:00<00:00, 1138.70it/s]\n",
      "Preparing scene by scene...: 100%|██████████| 405/405 [00:00<00:00, 1137.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits - Train: 324, Val: 40, Test: 41"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splits - Train: 324, Val: 40, Test: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find TrainUNet-Basic.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70e735e010b4f498b60b3a5e0e5cd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/testDataset/lst-benchmark/utils/model.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/work/ubh496/testDataset/lst-benchmark/utils/model.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find TrainUNet-Basic.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bd81c8f7e04811ac0b5d67785ad9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/testDataset/lst-benchmark/utils/model.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/work/ubh496/.conda/envs/ml/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [2, 768, 1, 1], strides() = [768, 1, 768, 768]\n",
      "bucket_view.sizes() = [2, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/work/ubh496/.conda/envs/ml/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [2, 768, 1, 1], strides() = [768, 1, 768, 768]\n",
      "bucket_view.sizes() = [2, 768, 1, 1], strides() = [768, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e4dfb95784a7f8f46391305c48a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303d5ce5b2424241a62b8a793d095427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "from torchgeo.trainers import PixelwiseRegressionTask\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import cv2\n",
    "import logging\n",
    "from typing import List\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, Callback\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "from utils.model import LSTNowcaster\n",
    "from utils.data.TiledLandsatDataModule import TiledLandsatDataModule\n",
    "from utils.voice import notifySelf\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"TrainUNet-Basic.ipynb\"\n",
    "os.environ[\"WANDB_DIR\"] = \"./wandb\"\n",
    "os.environ[\"WANDB_CACHE_DIR\"] = \"./wandb/.cache/wandb\"\n",
    "os.environ[\"WANDB_CONFIG_DIR\"] = \"./wandb/.config/wandb\"\n",
    "os.environ[\"WANDB_DATA_DIR\"] = \"./wandb/.cache/wandb-data\"\n",
    "os.environ[\"WANDB_ARTIFACT_DIR\"] = \"./wandb/artifacts\"\n",
    "import sys\n",
    "\n",
    "i = 1\n",
    "batchSize = 32\n",
    "deviceCount = 2\n",
    "# Get the first argument passed after the script name\n",
    "# if len(sys.argv) > 1:\n",
    "#     i = int(sys.argv[1])  # Convert string to integer\n",
    "#     batchSize = int(sys.argv[2])\n",
    "#     deviceCount = int(sys.argv[3])\n",
    "config = {\n",
    "    \"experiment_name\": \"test\",\n",
    "    \"debug\": True,\n",
    "    \"by_city\": False,\n",
    "    \"months_ahead\": 1,\n",
    "    \"tile_size\": 128,\n",
    "    \"tile_overlap\": 0.0,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"model\": \"segformer\",\n",
    "    \"backbone\": \"b5\",\n",
    "    \"dataset\": \"pure_landsat\",\n",
    "    \"augment\": True,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": batchSize,\n",
    "    \"pretrained_weights\": True,\n",
    "    \"deterministic\": True,\n",
    "    \"random_seed_by_scene\": 1,\n",
    "    \"in_channels\": 6,\n",
    "    \"only_train\": False,\n",
    "    \"skip_years\": []\n",
    "}\n",
    "\n",
    "# Original 12 experiments from results table in the research paper\n",
    "if i == 1:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b5\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 2:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b5\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 3:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b3\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 4:        \n",
    "    config[\"model\"] = \"segformer\"\n",
    "    config[\"backbone\"] = \"b3\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 5:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 6:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "#b3\n",
    "if i == 7:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 8:        \n",
    "    config[\"model\"] = \"deeplabv3+\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 9:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 10:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet50\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i == 11:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 1\n",
    "if i == 12:        \n",
    "    config[\"model\"] = \"unet\"\n",
    "    config[\"backbone\"] = \"resnet18\"\n",
    "    config[\"months_ahead\"] = 3\n",
    "if i <= -1:\n",
    "    pass\n",
    "else:\n",
    "    config[\"experiment_name\"] = f'Exp. #{i}-6 Channel: {config[\"model\"]},Month {config[\"months_ahead\"]}, {config[\"backbone\"]}'\n",
    "\n",
    "notifySelf(f'Starting {config[\"experiment_name\"]}!')\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"heat-island\",\n",
    "    name=config['experiment_name'],\n",
    "    log_model=\"best\",\n",
    "    save_code=True,\n",
    "    save_dir=\"./wandb\",\n",
    ")\n",
    "wandb_logger.log_hyperparams(config)    \n",
    "\n",
    "# Create model\n",
    "model = LSTNowcaster(\n",
    "    model=config[\"model\"], \n",
    "    backbone=config[\"backbone\"], \n",
    "    in_channels=config[\"in_channels\"], \n",
    "    learning_rate=config[\"learning_rate\"], \n",
    "    pretrained_weights=config[\"pretrained_weights\"]\n",
    ")\n",
    "\n",
    "class PercentageProgressCallback(Callback):\n",
    "    def __init__(self, total_epochs, experiment_name):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # Only run on main process\n",
    "        if trainer.is_global_zero:\n",
    "            current_epoch = trainer.current_epoch\n",
    "            if current_epoch % 20 == 0:\n",
    "                current_percentage = min(100, int(current_epoch / self.total_epochs * 100))\n",
    "                wandb.alert(title=\"Training Update\", \n",
    "                        text=f'{self.experiment_name} is at {current_percentage:.2f}%', \n",
    "                        level=wandb.AlertLevel.INFO)\n",
    "\n",
    "percentage_callback = PercentageProgressCallback(total_epochs=config[\"epochs\"], experiment_name=config[\"experiment_name\"])    \n",
    "wandb_run_id = wandb_logger.experiment.id    \n",
    "current_date = datetime.now()                \n",
    "date_string = current_date.strftime(\"%B%d\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"./wandb/heat-island/checkpoints/{wandb_run_id}_{date_string}\",\n",
    "    filename= f\"{wandb_run_id}_{date_string}_\" + \"{epoch:03d}_{val_rmse_F:.4f}\",\n",
    "    monitor=\"val_rmse_p\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False  # Also save the last model for comparison\n",
    ")\n",
    "allYears = [\"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "for year in config[\"skip_years\"]:\n",
    "    allYears.remove(year)\n",
    "# for subYears in [allYears[:5], allYears[5:]]:\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config['epochs'],\n",
    "    gradient_clip_val=0.5,\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=False,\n",
    "    # deterministic=config[\"deterministic\"],\n",
    "    num_sanity_val_steps=2,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, percentage_callback],\n",
    "    devices=deviceCount,                         # Use all 4 GPUs\n",
    "    accelerator=\"gpu\",                 # Use GPU acceleration\n",
    "    strategy=\"ddp_notebook\",                    # Use DistributedDataParallel\n",
    "    precision=\"16-mixed\"               # Add mixed precision for memory efficiency\n",
    ")                             \n",
    "\n",
    "data_module = TiledLandsatDataModule(\n",
    "    data_dir=\"./Data\",\n",
    "    monthsAhead=config[\"months_ahead\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=8,\n",
    "    byCity=config[\"by_city\"],\n",
    "    debug=config[\"debug\"],\n",
    "    tile_size=config[\"tile_size\"],\n",
    "    tile_overlap=config[\"tile_overlap\"],\n",
    "    augment=config[\"augment\"],\n",
    "    seedForScene=config[\"random_seed_by_scene\"],\n",
    "    onlyTrain = config[\"only_train\"],\n",
    "    includeYears=allYears\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "# Train model\n",
    "trainer.fit(model=model, datamodule=data_module)\n",
    "\n",
    "# Register the best model as a W&B artifact\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24922568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/ubh496/.conda/envs/ml/lib/python3.10/site-packages/torch/__init__.py:1113: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 completed. CUDA memory allocated: 0.00 GB\n",
      "CUDA memory reserved: 0.00 GB\n",
      "unable to send email...\n",
      "(535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials af79cd13be357-7cd468e5c38sm1282163785a.115 - gsmtp')\n"
     ]
    }
   ],
   "source": [
    "# If you need to run multiple experiments using arguments, free GPU memory with this...\n",
    "# Force garbage collection and clear CUDA cache\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# # After deleting objects\n",
    "# for i in range(torch.cuda.device_count()):\n",
    "#     with torch.cuda.device(i):\n",
    "#         torch.cuda.empty_cache()\n",
    "# del model\n",
    "\n",
    "# # Force garbage collection and clear CUDA cache\n",
    "# import gc\n",
    "# for obj in gc.get_objects():   \n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) and obj.device.type == 'cuda':\n",
    "#             del obj\n",
    "#     except:\n",
    "#         pass\n",
    "# gc.collect()\n",
    "\n",
    "# # After deleting objects\n",
    "# for j in range(torch.cuda.device_count()):\n",
    "#     with torch.cuda.device(j):\n",
    "#         x = torch.zeros(1024, 1024, 1024, device=f'cuda:{j}')\n",
    "#         del x\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.reset_peak_memory_stats()\n",
    "#         torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "# # 4. Wait for GPU processes to complete\n",
    "# torch.cuda.synchronize()\n",
    "\n",
    "# # Print memory stats for debugging\n",
    "# if torch.cuda.is_available():\n",
    "#     print(f\"Loop {i} completed. CUDA memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "#     print(f\"CUDA memory reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "# notifySelf(\"Batch experiment ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9939165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./wandb/heat-island/checkpoints/yekyxa2u_May23/yekyxa2u_May23_epoch=001_val_rmse_F=15.4719.ckpt']\n",
      "unable to send email...\n",
      "(535, b'5.7.8 Username and Password not accepted. For more information, go to\\n5.7.8  https://support.google.com/mail/?p=BadCredentials af79cd13be357-7cd468e3fe2sm1279468585a.113 - gsmtp')\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁██</td></tr><tr><td>train_rmse_F</td><td>█▁</td></tr><tr><td>train_rmse_P</td><td>█▁</td></tr><tr><td>trainer/global_step</td><td>▁▁██</td></tr><tr><td>val_rmse_F</td><td>█▁</td></tr><tr><td>val_rmse_p</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_rmse_F</td><td>18.3223</td></tr><tr><td>train_rmse_P</td><td>3.89718</td></tr><tr><td>trainer/global_step</td><td>479</td></tr><tr><td>val_rmse_F</td><td>15.47193</td></tr><tr><td>val_rmse_p</td><td>3.59766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Exp. #1-6 Channel: segformer,Month 1, b5</strong> at: <a href='https://wandb.ai/jesus-guerrero-ml/heat-island/runs/yekyxa2u' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island/runs/yekyxa2u</a><br> View project at: <a href='https://wandb.ai/jesus-guerrero-ml/heat-island' target=\"_blank\">https://wandb.ai/jesus-guerrero-ml/heat-island</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/wandb/run-20250523_230613-yekyxa2u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "checkpoint_dir = f\"./wandb/heat-island/checkpoints/{wandb_run_id}_{date_string}\"\n",
    "checkpoint_files = glob.glob(f\"{checkpoint_dir}/*.ckpt\")\n",
    "print(checkpoint_files)\n",
    "best_model_path = checkpoint_files[0]\n",
    "if best_model_path and os.path.exists(best_model_path):\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f\"{best_model_path.split('/')[-1].replace('=','.')}\", \n",
    "        type=\"model\",\n",
    "        description=f\"Best model at {best_model_path.split('/')[-1]}\" \n",
    "    )\n",
    "    artifact.add_file(best_model_path)\n",
    "    wandb_logger.experiment.log_artifact(artifact)\n",
    "else:\n",
    "    print(\"Best model not found...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7445130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notifySelf(f\"Finished {config['experiment_name']}...\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
